{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04371388",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec9317c5",
   "metadata": {},
   "source": [
    "### Fundamentals I\n",
    "\n",
    "#### a) Conditional Probabilities\n",
    "\n",
    "In a computer science course, the instructors offer a voluntary tutorial which offers additional exercises. 70\\% of all students in the course attend the tutorial. 80\\% of the students pass the exam.\n",
    "\n",
    "The following matrix _grade_tutorial_ describes your data. The first column describes if the person attended the tutorial (or not) and the second one their grade (scale from 1 to 5, lower=better).\n",
    "\n",
    "Calculate the probability that a student attended the tutorial if we know that the person passed the exam (grade 4 or better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3899e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [0, 3],\n",
       "       [1, 5],\n",
       "       [0, 4],\n",
       "       [0, 5],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       [0, 5],\n",
       "       [1, 1],\n",
       "       [0, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "grade_tutorial = np.array([[True, 2], [False, 3], [True, 5], [False, 4], [False, 5], [True, 1], [True, 2], [True, 2], [False, 5], [True, 1], [False, 5]])\n",
    "grade_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb61cf",
   "metadata": {},
   "source": [
    "##### Theoritical calculation,\n",
    "\n",
    "prob of student attended the tutorial = P(A)  \n",
    "prob of student pass the exam = P(B)  \n",
    "P(A) = 6/11  \n",
    "p(B) = 7/11  \n",
    "P(A ‚à© B) = 5/11  \n",
    "P(A | B) = P(A ‚à© B) / P(B)  \n",
    "         = 5/11  / 7/11   = 5/7  = 0.714\n",
    "\n",
    "\n",
    "##### The code that can be used to calculate the answer is attached here,  (there are 2 methods to solve the task)\n",
    "\n",
    "###### method 1:\n",
    "\n",
    "P_A = grade_tutorial[:,0] == True  \n",
    "P_A = [i for i in P_A if i==True]  \n",
    "P_A = len(P_A) / len(grade_tutorial[:,0])  \n",
    "\n",
    "P_B = grade_tutorial[:,1] < 5  \n",
    "P_B = [i for i in P_B if i==True]  \n",
    "P_B = len(P_B) / len(grade_tutorial[:,0])  \n",
    "\n",
    "AandB = []  \n",
    "for i in grade_tutorial:   \n",
    "    if(i[1] < 5) and (i[0] == True):  \n",
    "        AandB.append(True)  \n",
    "p_AandB = len(AandB)/len(grade_tutorial[:,0])  \n",
    "P_A_cond_B = p_AandB / P_B  \n",
    "print(P_A_cond_B)  \n",
    "\n",
    "###### answer : 0.714\n",
    "\n",
    "###### method 2:\n",
    "\n",
    "pb = np.count_nonzero(grade_tutorial[:,1] < 5)/ np.size(grade_tutorial[:,0])  \n",
    "pr = np.count_nonzero(grade_tutorial[grade_tutorial[:,0]== False][:,1] < 5)/ np.size(grade_tutorial[:,0])  \n",
    "np.array([(pb - pr)/pb])  \n",
    "\n",
    "###### answer : 0.714\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca13dab",
   "metadata": {},
   "source": [
    "#### b) Logistic Regression with Regularization\n",
    "\n",
    "Consider the Logistic Regression classifier from exercise sheet 1. Extend it to support L2 regularization with hyperparameter $\\lambda$ (add your original code from sheet 1 and mark in a comment your changes). What is the purpose of this regularization? How do you chose the value of $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db1069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the purpose of the rugularization is to reduce overfitting problem, for better generalization\n",
    "# the value of lambda can be chosen using several methods. we can use a validation dataset, and use the training and validation\n",
    "# losses (curves) for tunning the hyperparameter lambda(L2 regularization), here training and validation losses can be used to\n",
    "# detect overfitting and lembda can be changed to reduce that overfitting, that way a good vlaue for lambda can be determined.\n",
    "# else we can also use k-fold cross validation to tune or select a suitable hyperparameter lambda value\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, verbose=False, Lambda=0.1):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.verbose = verbose\n",
    "        self.Lambda = Lambda\n",
    "\n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        z = h = np.clip(z, EPS, 1-EPS)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def __loss(self, h, y):\n",
    "        h = np.clip(h, EPS, 1-EPS)\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h) ).mean()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.__add_intercept(X)\n",
    "        self.theta = np.random.rand(X.shape[1])\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T,(h - y)) / y.size\n",
    "            self.theta = self.theta - self.lr * gradient  - self.lr*self.Lambda*self.theta / y.size   # added regularization term here\n",
    "\n",
    "            if (self.verbose == True and i % 10000 == 0):\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print(f'loss: {self. __loss(h, y)} \\t')\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        X = self.__add_intercept(X)\n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34058384",
   "metadata": {},
   "source": [
    "#### c) Transfer of Fundamentals\n",
    "\n",
    "In the fundamentals lecture, we covered many topics from \"traditional\" machine learning. However, many of these concepts re-appear when studying neural networks. For the following list of concepts, give an example in 2-3 sentences each of how the respective concept is relevant to studying neural networks. Your example can be a direct use of the method or an analogy/extension/generalization.\n",
    "\n",
    "i) Decision Tree\n",
    "\n",
    "ii) Gaussian Distribution\n",
    "\n",
    "iii) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f4489",
   "metadata": {},
   "source": [
    "i)\n",
    "Decision Tree is relatively interpretable machine learning method useful for non linear classification. Neural networks are black box models. Decision trees can be used for XAI(explainable AI). For example, Decision Trees can be used to add interpretion to neural network based AI.\n",
    "\n",
    "ii)\n",
    "Gaussian Distribution is useful for Generative models. For example, gaussian distribution is used in Variational Autoencoders. Here the Prior distribution $P_{\\theta‚àó}(ùíõ)$ is implemented as a parameterized distribution of a known family; usually a gaussian distribution. Another example is the use of gaussian distribution in GAN. Here a noise vector ùíõ($) is sampled from a\n",
    "known distribution; usually standard gaussian distribution. \n",
    "\n",
    "iii)\n",
    "PCA can be used for feature compression (and also dimentionality reduction - without much loss of information) of the input data to a neural network. PCA can identify the most important input feature components(explain the maximum of variance in data), and neglect noise input components for a neural network. This can help to improve the training duration and accuracy of a neural network.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9703abe",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02efacc2",
   "metadata": {},
   "source": [
    "### Fundamentals II\n",
    "\n",
    "#### a) Data Split\n",
    "Please explain the differences between training, validation, and test data sets w.r.t. their purposes. How would you split a dataset into those three subsets (in terms of portions) and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f488cbe",
   "metadata": {},
   "source": [
    "In supervised learning, the data is usually seperated into three sets i.e Training, Validation and Test.\n",
    "\n",
    "Training dataset: Training set is used to train the model(tune the parameters). During the trtaining process, in each epoch the training algorithm goes through each sample in the training set.\n",
    "\n",
    "Validation dataset: Validation set is  not used to train the model but to evaluate the model performance during the training process. This set is often used to tune the hyperparametrs (learning rate, number of layers, model architecture etc.)\n",
    "\n",
    "Testing dataset: Testing set is used to evaluate the performance of a fully trained model.\n",
    "\n",
    "Spliting: Usually largest portion of data should be allocated for the training because parameter training is data intensive. Remaining data can be split into two equal sets i.e Validation and Test. Heere are some examples,\n",
    "Ex1:\n",
    "Train : 70%, Validation: 15%, Test: 15%\n",
    "Ex2:\n",
    "Train : 80%, Validation: 10%, Test: 10%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14aa075c",
   "metadata": {},
   "source": [
    "#### b) Principal Component Analysis (PCA)\n",
    "Can you apply PCA as feature selection method? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c56764",
   "metadata": {},
   "source": [
    "PCA does not select a subset from the number of features. What is does is essentially transforming the feature space to a new feature space with reduced dimensions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b1fb685",
   "metadata": {},
   "source": [
    "#### c) Normalization \n",
    "Why is it important to normalize your data, especially when you have multiple input features? Please give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8522c",
   "metadata": {},
   "source": [
    "Because different features might have different scalings. In this case features with high variance can dominate the distance measurement and therefore bias the result. To overcome this Normalization techniques(such as Z normalization) can be employed.\n",
    "\n",
    "For example\n",
    "- Consider 'Age' and 'Income' as features.\n",
    "- Consider two persons, one with Age=30 and Income=50000, and the other with Age=60 and Income=55000\n",
    "- Eventhough the numerical difference between two incomes is much larger than that for the Age, intuitively we know that the Age diffence here is much more significant.\n",
    "- If Z normalization is employed here, it transforms all the feature data into distrubutions with 0 as mean and 1 as standard deviation. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "274f3e89",
   "metadata": {},
   "source": [
    "#### d) Evaluation \n",
    "We are classifying 100 people having either COVID-19 or not. 30 people among 100 have all the symptoms of COVID-19 and are positive rest of the 70 people have only flu. \n",
    "Suppose we are using a Machine Learning (ML) classifier and it correctly classified 20 people as COVID positive out of 30 people. The remaining 10 people are not classified as COVID positive. On the other hand 70 people who are only having flu, 55 are classified as no COVID and remaining 15 are classified as COVID positive.\n",
    "\n",
    "i) Calculate accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Now suppose the ML classifier has correctly classified the 70 people as COVID negative but it also has classified all the remaining 30 people (who are COVID positive) negative as well.\n",
    "\n",
    "ii) Calculate the accuracy.\n",
    "\n",
    "iii) Is the accuracy giving a correct measure? Briefly discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de487ab",
   "metadata": {},
   "source": [
    "i)  \n",
    "T.P = 20, F.P = 15, T.N = 55, F.N = 10   \n",
    "Accuracy = (T.P + T.N)/(T.P + T.N + F.P + F.N) = 75/100 = 0.75 = 75%  \n",
    "Precision = T.P/ (T.P + F.P) = 20/35 = 0.57 =57%  \n",
    "Recall = T.P/(T.P + F.N) = 20/30 = 0.67 = 67%  \n",
    "F1 score = 2.(Precision.Recall)/(Precision+Recall) = 0.62\n",
    "\n",
    "ii)\n",
    "T.P = 0, F.P = 0, T.N = 70, F.N = 30\n",
    "Accuracy = (T.P + T.N)/(T.P + T.N + F.P + F.N) = 70/100 = 0.7 = 70%\n",
    "\n",
    "iii)\n",
    "It does not give a correct measure about the model performance. An accurancy of 70% gives the idea that the classifier works reasonably well, but it infact it does not identify covid patients at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bad03",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7e67403",
   "metadata": {},
   "source": [
    "### End-to-End/Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "688b07c3",
   "metadata": {},
   "source": [
    "#### a) QUESTIONS \n",
    "\n",
    "| Model | 1. | 2. | 3. | 4. |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Train Accuracy | 0.71 | 0.85 | 0.5 | 0.85 |\n",
    "| Test Accuracy | 0.7 | 0.8 | 0.5 | 0.4 |\n",
    "\n",
    "\n",
    "Let's say, you're training a neural network to classify male and female dwarves. Your dataset is difficult: a person manages to achieve only a 85% accuracy on it. At different stages during the development of your model you achieve the following four train, test error tuples. \n",
    "\n",
    "**1. Explain why you would look at the train and test accuracy, what the difference between them is, and how they relate to the error of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac7cfd",
   "metadata": {},
   "source": [
    "- Train accuaracy is the accuracy calculated during training, after each training epoch, using the training dataset (dataset that is used to train the model) and Test accuracy is the accuracy measured once the training is done using test dataset(this should contain unseen data to the model).\n",
    "\n",
    "- When the train and test accuracies are similar and high then it can be considered a model without bias and variance and therefore a good model.\n",
    "\n",
    "- When the train and test accuracies are similar and low, then it is probably a model with high bias.\n",
    "\n",
    "- When the train accuracy is significanty higher than the test accuracy and both values are relatively high, then it is probably a model with overfitting problem.\n",
    "\n",
    "- When the train accuracy is significanty higher than the test accuracy and both values are relatively low, then it is probably a model with overfitting high bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b8b4f",
   "metadata": {},
   "source": [
    "The figure below describes the behaviour of Bias/Variance/Test Error (=the three curves) in relation to model complexity (increased through model training).\n",
    "\n",
    "\n",
    "**2.1 Name each of the three curves (red, blue, black) in the figure.** <br>\n",
    "**2.2 What does the dotted line represent?** <br>\n",
    "**2.3 Where in the figure would you place the Models 1-4 from Question 1? Sort the models from left most position in the image to right most.** <br>\n",
    "\n",
    "\n",
    "![Figure C](bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff480788",
   "metadata": {},
   "source": [
    "<b>2.1</b>  \n",
    "Blue - Bias  \n",
    "Red - Variance  \n",
    "Black - Test error\n",
    "\n",
    "<b>2.2</b>  \n",
    "Optimum model complexity\n",
    "\n",
    "<b>2.2</b>  \n",
    "3,1,2,4 from left to right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab298d",
   "metadata": {},
   "source": [
    "**3. Explain what an End-to-End Deep Learning System is by discussing an example in the context of Automatic Speech Recognition**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59fab1",
   "metadata": {},
   "source": [
    "In case of Automatic Speech Recognition, a lagacy system would have multiple components that are systems on their own, such as Accoustic model, Phonetic dictionary and languague model, along the pipeline.  \n",
    "In case of an End-to-End system, the whole system will be replaced by a single neural network. In this specific case can be realized by using Recurrent Neural Networks with techniques such as LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "776824c4",
   "metadata": {},
   "source": [
    "**4.Consider the following scenario: The superhero Batgirl (who is mute and communicates in American Sign Language) wants to solve a crime and the only relevant witness is a blind person who only speaks Japanese. She hires you and asks you to build a system that will enable her to interrogate this witness.**\n",
    "\n",
    "i) How would your system look like that is solving this task? Give a *rough* outline of both: an End-to-End system as well as a modular system (input/output and involved processes/modules (rough) for each system).\n",
    "\n",
    "ii) What are the advantages/disadvantages of each of your systems (End2End vs modular) you described in a)?\n",
    "\n",
    "- For (i): Make sure to identify all sub-problems your system needs to tackle in order to appropriately solve the described task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2562af",
   "metadata": {},
   "source": [
    "i) \n",
    "To allow communication between two, the system should translate bi-directionally between American sign language and Japanese  \n",
    "This includes:  \n",
    "ASL to Japanese: Recognize ASLlanguage content that comes in the form of visuals(sequence of signs), translate that into Japanese and output it to the witness in the form of speech  \n",
    "Japanese to ASL: Recognize Japanese content that comes in the form of speech from the witness, translate it into American sign language and display the output to the superhero Batgirl(as a sequence of signs)\n",
    "\n",
    "End-To-End system:  \n",
    "The end to end system can have Seq2Seq network with attention(for the translation task - encoder decoder architecture) at the core and two convolutional network at the input and output. \n",
    "Sequence of images(input) -> (Conv. nn -> RNN/LSTM -> RNN/LSTM -> Conv. nn) -> Speech output\n",
    "\n",
    "Modular system:\n",
    "This can be realized using a modular SMT system and the model would have the following modules.\n",
    "\n",
    "Image encoder/decoder system - feturerize the input images and construct output images\n",
    "decoder  \n",
    "language model(for both languages)  \n",
    "translation model(for both languages)  \n",
    "Training data  \n",
    "\n",
    "\n",
    "ii)\n",
    "Advantages(w.r.t the end-to-end system)  \n",
    "- determines useful features by itself\n",
    "- does not need module specific expertise in troubleshooting\n",
    "\n",
    "Disadvantages(w.r.t the end-to-end system)  \n",
    "- sophisticated, single task oriented systems cannot be used\n",
    "- data intensive\n",
    "- troubleshooting involes the full model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fc9914",
   "metadata": {},
   "source": [
    "#### b) IMPLEMENTATION\n",
    "**1) Use the following code cell to implement your own *binary* Cross-Entropy loss function. <br>**\n",
    "\n",
    "**Note: Read and solve task 2) first to avoid potential confusion!**\n",
    "\n",
    "- Do not change existing code, only add your code. Follow the hints in the comments.\n",
    "- Implement BINARY cross-entropy loss. There will be NO points for implementing categorical CE!\n",
    "- Do NOT use loops when implementing the loss function (no \"for\", \"while\")! We will deduct points if loops are used!\n",
    "- The solution to task (2) might influence how you tackle this task (1), so read (2), as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec520c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCrossEntropyLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.para = params\n",
    "\n",
    "    def forward(self, y_predicted, y_target):\n",
    "        y_predicted = F.softmax(y_predicted, dim=1)\n",
    "        \n",
    "        ### start; your code here\n",
    "        # cross-entropy term\n",
    "        # take log of predicted output probabilities of your samples and then multiply with target vectors\n",
    "        # for stability: add a small epsilon before taking log to avoid nan values when taking log of 0\n",
    "        eps = 1e-8\n",
    "        \n",
    "        # following is a vectorized implementation where the whole calculation is done in one line\n",
    "        loss = torch.mean(-y_target * torch.log(y_predicted + eps) - (1 - y_target)*torch.log(1 - y_predicted + eps))\n",
    "\n",
    "        # sum CE loss over all samples\n",
    "        \n",
    "        # take average of the CE sum to get avg loss per sample\n",
    "         \n",
    "        # negate the result\n",
    "        \n",
    "        ### end of your code; \n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a4a5e",
   "metadata": {},
   "source": [
    "**2) There is an issue in the code which is provided in task 1), which conflicts with an implementation of binary CE loss. Point out the problematic code and explain the issue.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881136ae",
   "metadata": {},
   "source": [
    "Binary CE loss should be implemented with Sigmoid function applied on the predictions before the loss calculation. But, in the code there is a Softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031e761",
   "metadata": {},
   "source": [
    "**3) Use the following code cell to implement the stochastic gradient descent optimizer with momentum and dampening as given by the following weight update rule: <br>**\n",
    "\n",
    "$$v_t \\leftarrow momentum * v_{t-1} + (1-dampening) dW_t$$ <br>\n",
    "$$W_{t+1} \\leftarrow W_t-learning\\_rate * v_t$$\n",
    "\n",
    "\n",
    "**Grading conditions / important notes:**\n",
    "- Make sure that your code is actually working without errors. We will deduct points if it doesn't!\n",
    "- Make sure that your code is actually optimizing a given network and parameters work as intended. You can test this by comparing training with your optimizer code with the official implementation (torch.optim.SGD) using the same parameters. Results should be similar if not identical (set same torch.manual_seed(0) for each run to ensure same conditions). If results are significantly different, there might be an issue. We will deduct points if your code has issues (deduction will depend on severity of issues).\n",
    "- Tip: Use the Exercise Sheet 2 (optimizer task) as environment to test your function more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ac7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Optimizer\n",
    "class MyMomentumOptimizer(Optimizer):\n",
    "    \n",
    "    def __init__(self, params, lr=0.001, momentum=0.9, dampening=0):  \n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening)\n",
    "        super(MyMomentumOptimizer, self).__init__(params, defaults)\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            dampening = group['dampening']\n",
    "            momentum = group['momentum']\n",
    "            lr = group['lr']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                if p.grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients.')\n",
    "                # get the state (a python dict) of the optimizer \n",
    "                # this dict contains last iteration's values for velocity and tracks step count\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    # initialize in first iteration\n",
    "                    state['step'] = 1\n",
    "                    state['velocity'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                else:\n",
    "                    state['step'] += 1\n",
    "                    \n",
    "                ### start; your code here                \n",
    "\n",
    "                # calculate new velocity using past velocity, current gradient and momentum/dampening terms\n",
    "                velocity = state['velocity']\n",
    "                velocity = velocity * momentum + (1-dampening) * p.grad\n",
    "                # store new velocity in state variable for next iteration\n",
    "                state['velocity'] = velocity\n",
    "\n",
    "                \n",
    "                \n",
    "                # update current weights in p.data\n",
    "                p.data = p.data - lr * velocity\n",
    "                ### end of your code;\n",
    "\n",
    "        return "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b941751",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Recurrent Neural Networks (RNN)\n",
    "\n",
    "#### a) Model Definitions \n",
    "In the following code cell, different models that can be trained and tested on the CIFAR-10 dataset are implemented. <br>\n",
    " <br>\n",
    "The first model is a Recurrent Neural Network with the following properties: \n",
    "   - 2 hidden layers\n",
    "   - tanh nonlinearity\n",
    "\n",
    "The second model is a custom model. Have a close look at both implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f0a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "input_dim = 32\n",
    "hidden_dim = 100 # for example\n",
    "rnn_layer_dim = 2 \n",
    "output_dim = 10 \n",
    "\n",
    "# The RNN\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        # Building your RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        if th.cuda.is_available():\n",
    "            h0 = th.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()\n",
    "        else:\n",
    "            h0 = th.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "\n",
    "        #Define the forward steps\n",
    "            \n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = output_dim\n",
    "        self.W = nn.Parameter(th.Tensor(input_dim, output_dim * 4))\n",
    "        self.U = nn.Parameter(th.Tensor(output_dim, output_dim * 4))\n",
    "        self.bias = nn.Parameter(th.Tensor(output_dim * 4))\n",
    "        self.init_weights()\n",
    "                \n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "         \n",
    "    def forward(self, x, \n",
    "                init_states=None):\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            x1, x2 = (th.zeros(bs, self.hidden_size).to(x.device), \n",
    "                        th.zeros(bs, self.hidden_size).to(x.device))\n",
    "        else:\n",
    "            x1, x2 = init_states\n",
    "         \n",
    "        HS = self.hidden_size\n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            gates = x_t @ self.W + x1 @ self.U + self.bias\n",
    "            x3, x4, g_t, x5 = (\n",
    "                th.sigmoid(gates[:, :HS]), \n",
    "                th.sigmoid(gates[:, HS:HS*2]), \n",
    "                th.tanh(gates[:, HS*2:HS*3]),\n",
    "                th.sigmoid(gates[:, HS*3:]), \n",
    "            )\n",
    "            x2 = x4 * x2 + x3 * g_t\n",
    "            x1 = x5 * th.tanh(x2)\n",
    "            hidden_seq.append(x1.unsqueeze(0))\n",
    "        hidden_seq = th.cat(hidden_seq, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        return hidden_seq, (x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d015e",
   "metadata": {},
   "source": [
    "i) Give a better name for the CustomModel that describes how this architecture is commonly called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20db80c",
   "metadata": {},
   "source": [
    "LSTM architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d373b3",
   "metadata": {},
   "source": [
    "ii) What are more appropriate, descriptive variable names for x1, x2, x3, x4, and x5? Make clear which new variable name replaces the old one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbee8cf",
   "metadata": {},
   "source": [
    "- x1: hidden_state\n",
    "- x2: cell_state\n",
    "- x3: input_gate\n",
    "- x4: forget_gate\n",
    "- x5: output_gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de245d0",
   "metadata": {},
   "source": [
    "iii) Implement a Gated Recurrent Unit (GRU) with help of the pre-defined PyTorch layers, similar to how the given RNN model has been implemented (for GRU: Number of hidden layers=1, dropout rate=zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b154b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch as th\n",
    "\n",
    "input_dim = 32\n",
    "hidden_dim = 100 \n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout=0):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        # use built-in GRU module instead of RNN\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if th.cuda.is_available():\n",
    "            h0 = th.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()\n",
    "        else:\n",
    "            h0 = th.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        \n",
    "        # use built-in GRU module instead of RNN\n",
    "        out, hn = self.gru(x, h0)\n",
    "        \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d357b",
   "metadata": {},
   "source": [
    "iv) Consider the MNIST data set from the AML tutorials (handwritten digits from 0-9 in 28x28 pixels grayscale images). We apply a RNN or LSTM on this data for sequential processing of input images and perform a classification task. This would consider the current and previous pixels information. Would it be beneficial to also include the future pixel information? Independent of your answer, what architecture could be used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1c790",
   "metadata": {},
   "source": [
    "- Yes, it could be beneficial to include the future pixel information as well, because it might help in defininng the context better, by broadening the dependency considerations.  \n",
    "But on the other hand, it should be looked into whether the performance improvement outweight the costly calculations.\n",
    "\n",
    "- Bidirectional RNN/LSTM could be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d8c8c",
   "metadata": {},
   "source": [
    "#### b) Learnable Weights (4 points)\n",
    "i) How many learnable weights does the implemented RNN from task 4a have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908563e",
   "metadata": {},
   "source": [
    "learnable weights = 32x100 + 100x100 +100 + 100 + 100x100 + 100x100 + 100 + 100 + 100x10 + 10 = 34610"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1fa655",
   "metadata": {},
   "source": [
    "ii) How many would it have, if it only had one hidden layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7ffa5",
   "metadata": {},
   "source": [
    "learnable weights = 32x100 + 100x100 + 100 + 100 + 100x10 + 10 = 14410"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15144ea0",
   "metadata": {},
   "source": [
    "iii) How many dimensions does your input data must have, so that you can process it with a RNN? Give each dimension a name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf52bb6",
   "metadata": {},
   "source": [
    "3 dimensions\n",
    "\n",
    "1. Batch size  \n",
    "2. Sequence length  \n",
    "3. Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ee31f",
   "metadata": {},
   "source": [
    "iv) Why does adding more layers not necessarily improve the classification accuracy? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb40685",
   "metadata": {},
   "source": [
    "Adding more layers increase the number of learnable parameters and therefore the model can get too complex and easily overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90c94b",
   "metadata": {},
   "source": [
    "#### c) Exploding/Vanishing Gradients (2 points)\n",
    "i) Explain why RNNs are prone to the exploding and vanishing gradients problem (maximum: 5 sentences)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8147e",
   "metadata": {},
   "source": [
    "- Vanishing gradient problem is the problem where gradients diminishes exponentially, and The exploding gradient problem is the opposite of that, which causes gradients to grow exponentially, as back propagation algorithm progates backwards though the network.\n",
    "- This issues cause the training to take very long time and the calculation to go unstable respectively\n",
    "- This problems usually arises as neural networks get deeper. \n",
    "- Since RNNs are equivalent to relatively deep networks when unfolded this phenomenon is common in RNNs too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921790f",
   "metadata": {},
   "source": [
    "ii) Describe a method that could be used in order to counteract exploding gradients. How does this method work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb37a0",
   "metadata": {},
   "source": [
    "- To solve exploding gradients problem, gradient clipping can be used. In this method gradient exploding is avoided by rescalling the gradients  \n",
    "- As characteristics(derivative to be specific) of the activation function used(occurs usually in activation functions such as Sigmoid and tanh) contributes to this problem, vanishing gradient problem can be solved by using activation functions such as ReLU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431922f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "feaa6fdf",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNN)\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class.<br>\n",
    "Please **download** and unzip the dataset. ```Important:``` change the directory path in the following code cell. <br>\n",
    "First, we will do our imports, load the data and define a custom dataset. **Read** the following code cell carefully, it is used to prepare the data for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e4d2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"\"\n",
    "tr_dir = os.path.join(root_dir, 'cifar10_split', 'train')\n",
    "cv_dir = os.path.join(root_dir, 'cifar10_split', 'validate')  \n",
    "tt_dir = os.path.join(root_dir, 'cifar10_split', 'test')\n",
    "\n",
    "# Create datalist from directory for each subset\n",
    "tr_file_list = []\n",
    "cv_file_list = []\n",
    "tt_file_list = []\n",
    "\n",
    "# Load the training data\n",
    "for path, subdirs, files in os.walk(tr_dir):\n",
    "    for name in files:\n",
    "        file_dir = os.path.join(path, name)\n",
    "        label = path.split('\\\\')[-1]\n",
    "        tr_file_list.append(file_dir + ' ' + label)\n",
    "\n",
    "with open(os.path.join(root_dir, 'tr_data_list.txt'), 'w') as file:\n",
    "    for item in tr_file_list:\n",
    "        file.write(\"%s\\n\" % item)        \n",
    "        \n",
    "# Load the validation data\n",
    "for path, subdirs, files in os.walk(cv_dir):\n",
    "    for name in files:\n",
    "        file_dir = os.path.join(path, name)\n",
    "        label = path.split('\\\\')[-1]\n",
    "        cv_file_list.append(file_dir + ' ' + label)\n",
    "\n",
    "with open(os.path.join(root_dir, 'cv_data_list.txt'), 'w') as file:\n",
    "    for item in cv_file_list:\n",
    "        file.write(\"%s\\n\" % item)\n",
    "\n",
    "# Load the test data\n",
    "for path, subdirs, files in os.walk(tt_dir):\n",
    "    for name in files:\n",
    "        file_dir = os.path.join(path, name)\n",
    "        label = path.split('\\\\')[-1]\n",
    "        tt_file_list.append(file_dir + ' ' + label)\n",
    "\n",
    "with open(os.path.join(root_dir, 'tt_data_list.txt'), 'w') as file:\n",
    "    for item in tt_file_list:\n",
    "        file.write(\"%s\\n\" % item)\n",
    "\n",
    "#### Define custom dataset\n",
    "class cifar10Dataset(Dataset):\n",
    "    def __init__(self, data_list_path):\n",
    "        self.data_list_path = data_list_path\n",
    "        self.data_save_dirs = []            # Stores the save dirs for the images\n",
    "        self.labels = []\n",
    "        self.label_encoder = LabelEncoder() # Encodes strings to integers for classification\n",
    "        self._init_data()\n",
    "        \n",
    "    def __len__(self):                      # Get total number of dataset samples\n",
    "        return len(self.data_save_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):             # Return an item\n",
    "        data = io.imread(self.data_save_dirs[idx]) # Load image from hard disk\n",
    "        lab = self.labels[idx]              # Load class label\n",
    "        data = data.reshape(3, 32, 32).astype('float32') # Change to channels first and cast to float32\n",
    "        data = data/255.0                   # Normalize input\n",
    "        #print(data.shape)\n",
    "        #plt.imshow(cv2.cvtColor(data.reshape(32, 32, 3), cv2.COLOR_BGR2RGB))\n",
    "        return data, lab\n",
    "        \n",
    "    def _init_data(self):                   # Initialize data\n",
    "        with open(self.data_list_path, 'r') as file:\n",
    "            data_list = file.readlines()    # Read file list         \n",
    "                \n",
    "        for d in data_list:\n",
    "            s, l = d.split(' ')             # Split into input and label\n",
    "            self.data_save_dirs.append(s)\n",
    "            self.labels.append(l.rstrip('\\n'))\n",
    "        \n",
    "        # Encode string labels to integers\n",
    "        self.label_encoder.fit(self.labels)\n",
    "        self.labels = self.label_encoder.transform(self.labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e32a8fa0",
   "metadata": {},
   "source": [
    "#### a) Explain the Model  \n",
    "In the code cell below, a convolutional neural network is defined.\n",
    "Each question related to a specific line of code. These are marked in the code cell. Try to answer short and precisely.\n",
    "i) For the first convolutional layer what is the kernel size and the number of kernels. How many trainable weights does this layer consist of?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5921b9",
   "metadata": {},
   "source": [
    "kernel size = 5 or (5,5) \n",
    "number of kernels = 8 x 3 = 24  \n",
    "trainable weights has shape [8, 3, 5, 5]  , trainable bias has shape [8]   \n",
    "Total number of trainable weights = 8 x 3 x 5 x 5  = 600   \n",
    "\n",
    "Total number of trainable weights + bias = 8 x 3 x 5 x 5 + 8  \n",
    "                            = 608  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828af2f",
   "metadata": {},
   "source": [
    "ii) In your own words: What does a max pooling layer do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fcf5f",
   "metadata": {},
   "source": [
    "Max pooling reduces the size of an input feature map. The output feature map after a max-pooling layer contains the most prominent features (max values) of the previous feature map. This is achieved by the Maxpooling kernal, that selects the maximum value in the region of the feature map covered by the kernel.  \n",
    "Max pooling is used to reduce the dimensions of the feature maps. This can reduce the number of learnable parameters and the computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46b18d",
   "metadata": {},
   "source": [
    "iii) We introduced the CIFAR-10 dataset before in the introduction of this exercise. What is the correct output size of the final linear layer and why? Add this number in the code cell by replacing ```??```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85f018",
   "metadata": {},
   "source": [
    "correct output size should be 10 (since we have 10 numbers from 0 to 9 as our output class labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d7283",
   "metadata": {},
   "source": [
    "iv) What does this line of code do and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f13242",
   "metadata": {},
   "source": [
    "F.ReLu is the functional rectified linear activation function. This applies the ReLU activation function on the input data ('x'). Here the input to the ReLU activation function ('x') is the output data form the first convolution layer. \n",
    "After the application of this ReLU activation function, only the positive part of 'x' is remained, and the negative parts are set to zero. Application of a non linear (derivable) activation function is useful since this help the network to learn non linear relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6988a1e",
   "metadata": {},
   "source": [
    "v) Consider the output volume of the last convolutional layer. Before further processing from the dense layers, the output volume gets processed by a max pooling layer. Based on the output volume shape, what is the shape of the output volume after the max pool operation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d09ad9",
   "metadata": {},
   "source": [
    "after 2nd pool: the shape of the output is [5, 5, 16] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4adedc",
   "metadata": {},
   "source": [
    "vi) What does this line of code do and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c3667",
   "metadata": {},
   "source": [
    "it reshapes the tensor, or it returns a new tensor with the same data as the previous x tensor but of a different shape\n",
    "it change the x tensor form the shape [5, 5, 16]  to the shape [1, 400]\n",
    "this is because then it can be an input to a fully connected(dense) neural network with 400 input features (neurons)\n",
    "so each input sample should have the shape [1, 400] / need to have 400 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbc352",
   "metadata": {},
   "source": [
    "vii) What is the final size of the returned x? Describe how this output has to be processed further to get a label prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c950f",
   "metadata": {},
   "source": [
    "size is 10  (10 scalar values)\n",
    "This output has to be processed thourgh a softmax activation function layer to get the final label predcitions (probability) for each of the 10 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d26e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5)                                    #1\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=2)                  #2\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)                                       #3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)                                                      #4\n",
    "        x = self.max1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max2(x)                                                   #5\n",
    "        x = x.view(-1, 400)                                                #6\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x                                                           #7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cb370",
   "metadata": {},
   "source": [
    "#### b) Model Training (5 points)\n",
    "\n",
    "Give a step by step description of the training loop for one batch in one epoch. Explicitly state at which point the model is modified. Do not use code and explain the necessity of each step. (Bullet points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307ed14",
   "metadata": {},
   "source": [
    "\n",
    "before the training loop train, test, validation splits should be defined. And corresponding dataloaders should be prepared.\n",
    "The loss and optimizer should also be defined before the training loop.\n",
    "In the training loop,\n",
    "- First a batch of data(from the train set) is obtained using the data loader. This is important since it reduces memory resources usage by loading only one batch of data at once and not all data at once.\n",
    "- Then the gradients are cleared using the optimizer.zero_grad() method. This is important since by default PyTorch optimizer accumulates the gradients in buffers on subsequent backward passes whenever .backward() is called. This accumilation of gradients is useful in training. However, if this we  do not reset or clear the gradients at the start of training loop, previous loop gradient information will not be removed.\n",
    "- compute the model output. (Forward pass to get output) This is our predictions for the input data. \n",
    "- calculate the loss , specifically we can use the torch.nn.CrossEntropyLoss() here, since we have not implemented the softmax activation layer at the end of our model. torch.nn.CrossEntropyLoss() includes the LogSoftmax. This is also for multi class classification. So we can to use this CrossEntropyLoss(). \n",
    "- gradients are calculated using backpropagation. This gradient information is useful to perform a gradient based optimization algorithm (for example gradient descent).\n",
    "- update the model parameters. (important: At this step the model is modified). This step is important becasue here the optimizer (optimization algorithm ) uses the gradient information calculated in the previous step to adjusts the learnable parameters of the model. This is necessary since this improves the model's performance, it help to reduces the loss.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73832bee",
   "metadata": {},
   "source": [
    "#### c) example,\n",
    "You have 32,768 training samples, do Gradient Descent with 400 epochs and a batch size of 64. How often is every sample used for training? How often is the model updated during the entire training phase?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d353e9",
   "metadata": {},
   "source": [
    "This is a mini batch gradient descent. Therefore update of the model parameters happen after each batch.\n",
    "Number of epochs = 400  \n",
    "Therefore, every sample is used 400 times during the entire training phase.  \n",
    "Batch size = 64  \n",
    "Number of baches = 32,768/64 = 512  \n",
    "Therefore, the model is updated 512 times at each and every epoch.  \n",
    "Total number of model updates during the entire training phase = 512 x 400 = 204,800 times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bb6e946",
   "metadata": {},
   "source": [
    "#### d) Calculate Convolution\n",
    "\n",
    "Given the input A and the kernel K, calculate the two dimensional convolution result. Calculate the result only for fully overlapping positions (valid) between A and K (hence padding is not required). We define stride=1.\n",
    "\n",
    "![](Matrix_A.png) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ![](Kernel_K.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c4021",
   "metadata": {},
   "source": [
    "\n",
    "| 8  | 7  | 6  |\n",
    "|--- |--- |--- |\n",
    "| 22 | 7  | 23 |\n",
    "| 8  | 18 | 20 |\n",
    "\n",
    "calculation Eg:- $8 = 2*2+0*4+4*1+3*0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380ca91",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e1cbbb7",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f46c9ddb",
   "metadata": {},
   "source": [
    "#### a) Describe the advantages of an Encoder-Decorder with attention compared to an Encoder-Decoder without attention for a machine translation problem. Assume an LSTM encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f571c2",
   "metadata": {},
   "source": [
    "- Encoder-Decorder with attention can overcome Long-range dependency problem of the Encoder-Decorder without attention (LSTM encoder)\n",
    "- Attention based machine translation models provide better performance specially on long sentences compared to LSTM encoder-decoder based models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e956cbe",
   "metadata": {},
   "source": [
    "#### b) Can a transformer network, like its predecessors RNNs, LSTMs, process information one word at a time? What is its advantages compared to RNN/LSTM based model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38a301",
   "metadata": {},
   "source": [
    "\n",
    "Unlike RNN/LSTM based models, Transformer networks cannot process information one word at a time. Transformer processess a particular sentence as a whole or a sequence of words as a whole. In other words sentences are processed as a whole rather than word by word.\n",
    "\n",
    "Advantages of the Transformer Network: \n",
    "- can overcome the long-range dependency problem with RNN/LSTM\n",
    "- faster training than RNN/LSTM based models (attention reduces sequential operations and path length, transformers can have multi head attention - these heads don't share weights so can be train independently this provides some paralleliation)\n",
    "- Better performance than RNN/LSTM based models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64c4d262",
   "metadata": {},
   "source": [
    "#### c) Why do we add position encodings to Transformer inputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec469e",
   "metadata": {},
   "source": [
    "For attention, the order of the words in the sequence is not important. However, for machine translation or language modeling this order of words also provides some essential inormation. Therefore, Position encodings are added to the Transformer inputs to obtain information about the order of words in a sentence.\n",
    "\n",
    "Position encodings can provide information about the position of each word in a sequence and distances between different words in that sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02b932",
   "metadata": {},
   "source": [
    "#### d) What is multi-head attention? What is the advantages of using multi-head attention in Transformers? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43385b3",
   "metadata": {},
   "source": [
    "Combining several attention mechanisms is called multi-head attention. These Multiple attentions provides the possibility of focusing on different positions in a word sequence and obtain information in multiple representation subspaces.\n",
    "\n",
    "Advantages of Multi-head attention,\n",
    "- One of the main advantage of the multi-head attention is the training stability, because multi-head attention has less number of layers than the single-head attention, when attending the same number of positions.\n",
    "- In Multi head attention, these heads don't share weights so can be train independently this provides some paralleliation(can perform attention multiple times in parallel), this can reduce training time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22dd3e37",
   "metadata": {},
   "source": [
    "#### e) How does BERT differ from the original Transformer? How do you use BERT for sentiment analysis (to classify whether a text is neutral, negative or positive)? Note: You just need to describe the the input to the model and how do you build the model for classification. Description of training setup, libraries ect. are not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761bb2e",
   "metadata": {},
   "source": [
    "\n",
    "Bidrectional Encoder Representation from Transformer (BERT) is a language model. BERT is used for language understanding tasks.\n",
    "BERT is essentially a trained transformer encoder stack (with 12 in the Base-version and 24 in the large version). In comparison, the original Transformer is formed of an encoder and decoder. Therefore, BERT uses a stack of encoders that are very similar to the original encoder of the transformer, but BERT contain no decoders.\n",
    "BERT is designed to pre-train bidirectional representations from a text  on both left and right context (learn the language and context, and training is bi-directional). That means, BERT learns information from both the left and the right side of a text. After that the pre-trained BERT model can be finetuned to learn the specific tasks.\n",
    "\n",
    "\n",
    "#### How To use BERT for sentiment analysis:\n",
    "\n",
    "Input to the model: \n",
    "- a larger text for pre-training (better generalization, language understanding)  \n",
    "- for fine-tunning for our special task(sentiment analysis) we can use a dataset of texts consisting of three classes, positive, negative and neutral, then this should be prepared according to the format needed for the BERT model. Further details are given below.\n",
    "\n",
    "How to build the model:\n",
    "\n",
    "pre-training step: (we can usually choose an already pre-trained BERT, we only have to load it form a liberary)  \n",
    "BERT must be trained initially on a large text (or a pre-trained model should be loaded initially - here we have to apply BERT tokenizer to use pre-trained tokenizers from the liberary). This pre-training gives BERT the ability to better understand the language. Pre-training also give the ability to learn variability in data patterns and helps to generalizes well on several NLP tasks. Here BERT learns information from both the left and the right side of a text, because the training is bi-directional.\n",
    "\n",
    "Then our data (for sentiment analysis) should be prepared according to the format needed for the BERT model. We already have the target labels. Furthermore here our data should be transformed by adding additional 'Input IDs', 'Attention mask', 'Token type IDs', etc to become an appropriate format that can be feed into the BERT model. Then a train and test split of the dataset can be formed. We can use an optimizer such as Adam optimzer to optimize the parameters of the BERT model. We can use a loss function such as Sparse Categorical Cross-entropy.\n",
    "\n",
    "Fine-tunning step:(train the BERT model for Sentiment Analysis)  \n",
    "The last step is to fine-tune the model using our dataset (for sentiment analysis). We should be careful about the number of epochs, since the model is already pre-trained. Higher number of epochs can lead to overfitting. We may have to use regularization as well.  \n",
    "Finally the fine-tunned BERT model can be tested on the test dataset. Check it classify the texts correctly to one of the tree categories(neurtal, positive or negative texts).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013deead",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b72c6319",
   "metadata": {},
   "source": [
    "### Distance Metric Learning (DML)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4eb760eb",
   "metadata": {},
   "source": [
    "**a) Triplet and Proxy NCA  loss**\n",
    "\n",
    "We go back to the paper Kang and Park (2020): \"ContraGAN: Contrastive Learning for Conditional Image Generation\". (https://arxiv.org/abs/2006.12681), in which metric learning is for an additional loss for training conditional GANs. \n",
    "In the first paragraph of Section 3.2, the authors argue why they did not use sample-based metric losses, e.g. the triplet loss, or proxy-based losses, e.g., the Proxy NCA loss.\n",
    "\n",
    "Briefly describe both the triplet and Proxy NCA loss using a maximum of 4 sentences each. You do not have to explain formulas, but can simply use descriptions of their mechanisms. A formula similar to Proxy NCA will be included in the next exercise. (2 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072acd0",
   "metadata": {},
   "source": [
    "Triplet loss  \n",
    "Triplet loss is based on the constraint satisfaction; the distance between the anchor and positive [$ d(v,v^+) $]  must be smaller than between the anchor and the negative [$ d(v,v^-) $].   \n",
    "We also include a margin term ' m ' to avoid neural network learning a trivial solution of mappings.  \n",
    "Then the loss is defined as the maximum between $ 0 $ and the constraint term $ d(v,v^+) + d(v,v^-) + m $.   \n",
    "This means if the constrain term not violated (smaller than zero) the overall loss is set to zero otherwise loss is larger than zero and the NN is updated using backpropagation.\n",
    "\n",
    "\n",
    "Proxy NCA loss\n",
    "The idea of proxy NCA loss is to use a smaller set of embeddings denoted as proxies (proxy verctors) insteard of using training data samples for positive and negative for an anchor. \n",
    "Here the proxy NCA loss is defined for a given anchor sample (anchor embedding), with a positive sample (same class as anchor) and multiple negative samples(different class).  \n",
    "We take the  expoential of the negative distance between anchor and positive proxy and, divide that by the sum of exponentials of negative distance of mutliple negative proxies(equal to the softmax over negative distances), and take the negative log.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3656b5ef",
   "metadata": {},
   "source": [
    "**b) NT-Xent loss** \n",
    "\n",
    "We will now look at the  NT-Xent loss, which is introduced in the next paragraph of Section 3.2. In this loss, a batch of $m$ data samples is first augmented to produce a batch of $2m$ samples, such that each second sample is an augmentation of the original sample (e.g., by random cropping for images, adding noise for audio, etc.). \n",
    "\n",
    "The loss computed on $a_i$, $a_j$, which are the original sample and the augmentation of the same sample, is depicted in Equation (6) of the paper.\n",
    "\n",
    "Explain: What does the loss value of $L(a_i, a_j, t)$ denote here, i.e. what kind of value is computed here. Explain how it is computed - you can refer to the NCA loss, which has a similiar structure. If you do so, please point out the difference between both losses. (2 points)\n",
    "\n",
    "Please note:\n",
    " - The NT-Xent loss is unsupervised and thus does not use any class information; \n",
    " - The embeddings $l(a_i)$ and $l(a_j)$ lie on a unit hypersphere, so $l(a_i) ^T l(a_j)$ computes the cosine similarity (not distance) between both embeddings. You can just assume that $l(a_i) ^T l(a_j)$ corresponds to $-d(l(a_i), l(a_j)$) to be consistent with the lecture.\n",
    " - You can also ignore the scalar $t$ in your explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76fec9",
   "metadata": {},
   "source": [
    "\n",
    "Here $a_i$ represents a original sample and  $a_j$ represents a augmentation of the same sample. Then NT-Xent loss is defined for $l(a_i) ^T l(a_j)$ provides the cosine similarity between the two embeddings. In comparison NCA loss uses the negative distance instard of cosine similarity.\n",
    "\n",
    "proxy NCA loss uses a softmax of negative distances to denote the how much of probability that anchor sample belongs to the same class as positive proxy,  and then take the negative log because we want to minimize the loss (maximize the probability will milimize the negative log, hence minimize the loss)\n",
    "\n",
    "Similarly here we can say that NT-Xent loss uses  softmax over cosise similarity (analogus to negative distances) to denote how much of probability that original sample and augmentation of the same sample are similar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94136635",
   "metadata": {},
   "source": [
    "**c) Conditional Contrastive Loss**\n",
    "\n",
    "We now look at the conditional contrastive loss (2C loss), which is the newly proposed loss function which is added to the normal adversarial loss when training GANs. In comparison to the  NT-Xent loss, it does not rely on data augmentation, but instead aims to additionally create a correspondence between data sample embeddings and class embeddings. As such, data class labels $y_i$ are mapped to $d$-dimensional embeddings $e(y_i)$, which have the same dimensionality as data sample embeddings $l(x_i)$. \n",
    "\n",
    "(i) Explain, first using Equation (7), how the loss models both sample-to-class and sample-to-sample\n",
    "relations and how the distances between embeddings are optimized. (2 points)\n",
    "\n",
    "(ii) What would happen if we would replace the second summand of the denominator of Equation 7 ($\\sum_{k=1}^{m} 1_{k \\neq i}  exp( l(x_i) ^T l(x_k)/t))$) with: $\\sum_{k=1}^{m} 1_{y_k \\neq y_i}  exp( l(x_i) ^T e(y_k)/t))$? (1 point)\n",
    "\n",
    "iii) Lastly, briefly explain why the summand ($\\sum_{k=1}^{m} 1_{y_{k} = y_{i}}  exp( l(x_i) ^T l(x_k)/t))$) is added to the numerator in Equation (8), leading to the final 2C loss. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193f951",
   "metadata": {},
   "source": [
    "\n",
    "i)  \n",
    "According to the paper, equation(6) requires proper data augmentations and equation(6) can not consider data-to-class relations of\n",
    "training examples. To solve this issues and to imporve the optimization, equation(7) uses the embeddings of class labels instead of using data augmentations of the equation(6). A class embedding function e(y) is used to reformulate the loss function in equation(6), this embedding function is used together with data sample embeddings $l(x_i)$ (product of them) to model the sample to class relation.\n",
    "the loss function models sample to sample reations using the terms $exp( l(x_i) ^T l(x_k)/t)$\n",
    "the loss function models sample to class reations using the terms $exp( l(x_i) ^T e(y_i)/t)$\n",
    "the distances between embeddings are optimized by pulling a reference sample $x_i$ nearer to the class embedding $e(yi)$ and pushing the others away.\n",
    "\n",
    "\n",
    "ii)  \n",
    "then the loss do not model sample to sample relations, it only model sample to class relations\n",
    "\n",
    "\n",
    "iii)  \n",
    "Eq. (7) pulls a reference sample xi nearer to the class embedding e(yi) and pushes the others away.\n",
    "This scheme may push negative samples which have the same label as yi. Therefore, we make an\n",
    "exception by adding cosine similarities of such negative samples in the numerator of Eq. (7). Therefore, the summand term is added to the numerator of equation(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588f1ae",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6705d267",
   "metadata": {},
   "source": [
    "### Reinforcement Larning (RL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5cfaee6",
   "metadata": {},
   "source": [
    "#### a) State and Action Space \n",
    "\n",
    "We want to create a RL agent to learn a strategy for one player in the game of Reversi (https://en.wikipedia.org/wiki/Reversi). Propose a definition for a state space $S$, a set of actions $A$, and a reward function $r$ for this purpose. Is the state space continous or discrete? Is the learning problem static and/or stochastic? (consider that there are two players)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b013f",
   "metadata": {},
   "source": [
    "- State space <b>S</b>:  Set of all board configurations (states <b>s: s‚ààS</b>) that could be leagally achieved from the start position of the game. In the case of Reversi it is approximately 10^28\n",
    "\n",
    "- Set of Actions <b>A</b>: Set of all valid actions (<b>a: a‚ààA</b>). An action would be transitting from a valid borad configuration (a state) to another board configuration following rules of the game.\n",
    "\n",
    "- Reward function <b>R(s,a)</b>: Reward function determines the immediate reward(could be 0) the agent gets for taking action <b>a</b> when the current state is <b>s</b>. Overall objective is to maximize the accumilative reward.\n",
    "\n",
    "- State space is <b>Discrete</b> since there is a finite number of states\n",
    "\n",
    "- Larning problem is <b>Synamic(Not Static)</b>, since the environment changes outside of agents control(there are two players) \n",
    "\n",
    "- Learning problem is <b>Deterministic(Not Stochastic)</b>\n",
    "\n",
    "References  \n",
    "Nees Jan van Eck‚àó, Michiel van Wezel, Application of reinforcement learning to the game of Othello, Computers & Operations Research 35 (2008) 1999 ‚Äì 2017"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6193f33e",
   "metadata": {},
   "source": [
    "#### b) Reward definition\n",
    "\n",
    "You use RL to train a robot to reach a goal in a complex environment. The robot receives a reward only at the end of an episode when it successfully reaches the goal. A colleague suggests to augment the reward function, giving additional partial rewards once the robot reaches certain waypoints which are close to the goal. Discuss the benefits and drawbacks of this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80058541",
   "metadata": {},
   "source": [
    "If the reward is given only at the end(sparse reward scheme) when the goal is achieved it could be very difficult and might take a very long time to train the model because feedbacks are rare.\n",
    "\n",
    "Insted, if the robot was awarded with a partial reward for intermediate goals or milestones(dense reward scheme), it would help to guide the robot towards its end goal, it could make training much faster becuase feedbacks are more frequnet now. This technique already exists and is called \"Reward shaping\" \n",
    "\n",
    "On the other hand this often requires domain knowledge. If the reward shaping was not engineered well, the robot might take actions (or stick to a certain set of actions) that would not contribute moving towwards the end goal, but just to maximize the reward.\n",
    "\n",
    "PS: One solution to this problem following paper discusses a scheme called \"Curiosity-driven Exploration\" where at the same time dense reward scheme is in place, it forces the agent to explore the environment in a meaningful way.\n",
    "Deepak Pathak, Pulkit Agrawal, Alexei A. Efros, Trevor Darrell Curiosity-driven Exploration by Self-supervised Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bb4bf",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11314084",
   "metadata": {},
   "source": [
    "###  Generative Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9ed629d",
   "metadata": {},
   "source": [
    "##### a) Variational Autoencoders \n",
    "i) Explain the principle of Maximum Likelihood (ML). Do not go into the details for the utilization of ML for a certain model, such as VAEs or GMMs, but instead explain the principle with a generative model variable `p_model`. \n",
    "\n",
    "ii) Explain the main loss (ELBO) for training variational autoencoders. In particular,  (1) what are the main components of the ELBO loss and (2) how are those components implemented in practice? \n",
    "Also, (3) why is the ELBO loss denoted as such?  \n",
    "\n",
    "Note: You do not have to show the complete derivation of the loss for the ML approximation here for full points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be940bc",
   "metadata": {},
   "source": [
    "\n",
    "i)  \n",
    "The generative model varible `P_model` denotes the probability assigned to the data by our model. Then the maximum likelihood principal is based on finding the model parameter set ($\\theta^*$) that maximuze the likelihood our data. If explained further, the aim is to find the model parameter set that provides the maximum product of probabilities for each data point in the dataset. Following equation can be used to explain it.  \n",
    "\n",
    "$Œò^* = ùëéùëüùëîùëöùëéùë•_\\theta \\  \\prod_{i = 1}^{n} P_{model}(x^{(i)};\\theta) $\n",
    "\n",
    "\n",
    "ii)  \n",
    "ELBO is used for optimizing variational autoencoders. Optimizing a variational autoencoder does not only mean using the mean squared error between the input sample and the reconstructed sample, but we have to also consider the latent space as well. Here we use the approximated log data likelihood. ELBO (Evidence Lower Bound) is the first part of this approximation as a lower bound of the true log data likelihood. The true data likelihood is the sum of ELBO and KL divergence between the encoder distribution [ $q_\\phi(z|x)$ ] and the true posterior distribution [ $p_\\phi(z|x)$]. Here we neglect the KL divergence and only optimize the ELBO, a lower bound of the true data likelihood (also if $q_\\phi(z|x)$ = $p_\\phi(z|x)$ KL divergence is zero)\n",
    "Then the ELBO becomes the main objective for optimization.\n",
    "\n",
    "ELBO [ $ùêø_{\\theta,\\phi}(x)$ ] is consists of two components. The first component is the likelihood of the reconstructed data given sample latents. We want to maximize this first component. The second compoent is the KL divergence between the encoder distribution [ $q_\\phi(z|x)$ ] and the prior distribution [ $P_\\theta(z)$ ]. We need to penalize if the encoders distribution [ $q_\\phi(z|x)$ ] diverges form the prior distribution [ $P_\\theta(z)$ ]. So we substract this part.\n",
    "\n",
    "For pratical implementation of the ELBO , we first use the MSE (mean squared error) for the first part of the ELBO loss and for the second part of ELBO loss we don't need to explicitly compute the KL divergence using the formula. For the second part we can assume KL divergence has a closed from solution of $ N(0,1) $ - a gaussian distribution of mean=0 and std=1. However if want we can also compute the KL divergence directly as well. The important point is the ELBO must be maximized (for better log data likelihood). But the practical implementation of the MSE (for example in pytorch) must be minimized to maximize ELBO (to achieve better reconstruction)\n",
    "\n",
    "why is the ELBO loss denoted as such?\n",
    "The ELBO is denoted as a such because it is a lower bound for the data likelihood , It is becasue the second part of data likelihood (KL divergence between the encoder distribution [ $q_\\phi(z|x)$ ] and the true posterior distribution [ $p_\\phi(z|x)$] ) is intractible since posterior distribution $P(ùíõ|x)$ is intractible. Therefore, ELBO is smaller than or equal to true data likelihood."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc8577f4",
   "metadata": {},
   "source": [
    "##### b)  Generative Adversarial Networks\n",
    "\n",
    "\n",
    "i) Explain main principle of generative Adversarial networks (GANs) in your own words (max. 5 sentences). The explanation must include the generator and discriminator network, as well how the generator learns to produce realistic samples. You do not have to use formulas in this explanation, but you are allowed to do so if you want. (2 points)\n",
    "\n",
    "ii) Please view Figure 1a) of the paper Kang and Park (2021): \"ContraGAN: Contrastive Learning for Conditional Image Generation\". (https://arxiv.org/abs/2006.12681). This figure depicts a conditional GAN, i.e. the GAN uses the class label as additional input. Explain how the class label is used in this architecture and why the generator might produce a higher-quality output. (2 points)\n",
    "\n",
    "Note:\n",
    "- Please ignore the other subfigures 1b) and 1c) for this exercise.\n",
    "- The explanation with full points does not require you to read the full ContraGAN paper nor the cited ACGAN paper. A brief description of the subfigure with guesses on the training scheme are adequate and why this might lead to better results is adequate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756c8b5",
   "metadata": {},
   "source": [
    "\n",
    "i)  \n",
    "Compared to variational autoencoders, GANs can generate data samples without modeling the data distribution. GAN consists of two main parts; a generator neural network (no real data input),and a discriminator neural network(input real dataset). The generator neural network uses random noise (for example with gaussian distribution) to generate new data(fake). Discriminator trys to spot (discriminate) this fake data from the real data. GAN can be considerd as a minimax game between the Generator and the Discriminator network.  \n",
    "\n",
    "ii)  \n",
    "The conditioal GAN uses the class label as additional input (using a auxiliary classifier), This auxiliary classifier can guide the generator to synthesize well-classifiable images. This can help the generator and, therefore not allow the discriminator to overpower the generator (ususlly the discriminator can otherwise overpower the generator.) and as a result this can improve the accuracy of the generator network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a2f2a",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd9f3541",
   "metadata": {},
   "source": [
    "### Probabilistic Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e406ee55",
   "metadata": {},
   "source": [
    "If help is needed beyond the contents of the lecture, search for an answer in the book \"Probabilistic Graphical Models\" by Daphne Koller and Nir Friedmann, freely available under https://djsaunde.github.io/read/books/pdfs/probabilistic%20graphical%20models.pdf .\n",
    "\n",
    "#### a) Evidence of Confidence? \n",
    "\n",
    "The most commong task in machine learning is to learn the expectation of a conditional distribution E(P(Y|X)). \n",
    "Howevery these kind of models are known to become less accurate and eventually fail in new situations.\n",
    "Why is that the case? Can you give a solution where the model is able to make the user aware of its uncertainty? Is there a solution to this problem overall? Try to argue mathematically!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44b909",
   "metadata": {},
   "source": [
    "The data taken from the real world are uncertain (sensors/actuators are unreliable), complex and also can be incomplete (contain certain insufficient information). This is because the real world is characterized by its high complexity and uncertainty. As a result, independent data are (from real world) also not truely available and data are also not identical in terms of size and structure.  \n",
    "Because of this reason expectation of a conditional distribution E(P(Y|X)) kind of models are known to become less accurate and eventually fail in new situations. \n",
    "\n",
    "Probabilistic graphical models can be used to capture this uncertainty. Probabilistic graphical models are also capable of learn, represent and reason about uncertain knowledge. However, Probabilistic graphical models only allow for fixed numbers of propositions.\n",
    "\n",
    "The solution:   \n",
    "The solution is the connecting of both statistical and relational models in Statistical Relational Learning (SRL). In othe words, we can use probabilistic logical models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22966552",
   "metadata": {},
   "source": [
    "#### b) Abstraction over more than numbers \n",
    "\n",
    "Take a look at the mutagenesis dataset (https://relational.fit.cvut.cz/dataset/Mutagenesis).\n",
    "In this dataset a molecule should be classified to be mutagenic or not. \n",
    "\n",
    "Describe a relational model that could classify molecules given their atoms, bonds and their respective features. What assumptions does your model have? How can it abstract to an unspecified number of atoms and bonds? Can neural networks be included in the model you described?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132658d",
   "metadata": {},
   "source": [
    "We would like to suggest a ensabmble of bayesian classifiers discussed in [1]. In the proposed method is an ensamble of bayesian classifiers. The model has three components. \n",
    "1. Local classification component\n",
    "2. Relational Classification Component\n",
    "3. Ensemble Classification Component\n",
    "Local classification component outputs the probability distribution over target variable based on ocal features and the Reational Classification component does the same with relational features. Ensamble component combines the output of the multiple classifiers. Each individual classifier would be a naive bayes classifier.\n",
    "\n",
    "Assumption: features are independent of each other\n",
    "\n",
    "A neural network alone cannot be used as it is a discriminative model, but may be used in a encoder-decoder configuration.\n",
    "\n",
    "[1]Preisach, C. and Schmidt-Thieme, L., 2008. Ensembles of relational classifiers. Knowledge and Information Systems, 14(3), pp.249-272.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034fd1f7",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b7e813f",
   "metadata": {},
   "source": [
    "###  Explainable AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "497307d7",
   "metadata": {},
   "source": [
    "#### a) Layerwise Relevance Propagation\n",
    "\n",
    "Read the paper \"What is relevant in a text document?: An interpretable machine learning approach\" (Arras et al., https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0181142). Answer the following questions:\n",
    "\n",
    "i) What is the output of the employed XAI approach and how can it be interpreted? What is a difference in relevance representation compared to the use of the method on image data, as introduced in the lecture?\n",
    "\n",
    "ii) How do the authors validate the employed XAI approach?\n",
    "\n",
    "iii) The employed network is a Convolutional Neural Network. Which special propagation rules of the XAI method need to be considered here, compared to a its application on a fully connected feed-forward architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7ae30",
   "metadata": {},
   "source": [
    "\n",
    "i)  \n",
    "\n",
    "The eployed XAI approach in this paper(layer-wise relevance propagation (LRP) method) outputs relevance scores that are viewed as highlighted text or a list of top-words in the document.\n",
    "\n",
    "The interpretation is achieved using a backward propagation procedure (layer-wise conservation principle) from the output prediction score that causes the classification of each possible target class, back to the input space.\n",
    "\n",
    "In other words, This can be interpretted as each intermediate classifier layer up to the input layer gets allocated relevance values, and the sum of the relevances per layer is equal to the classifier prediction score for the class being considered.\n",
    "\n",
    "\n",
    "The a difference in relevance representation compared to the use of the method introduced in the lecture is the messaging concept.\n",
    "In other words, most concepts are similar to that discussed in the lecture, except for the concept of messages,\n",
    "According to the paper, this concept of messages ($R_{a‚Üêb}$) can be explained as the relevance circulates from a given neuron 'b' to a neuron 'a' in the next lower layer. Then the relevance of neuron 'a' can be expressed according to the paper as a sum of incoming messages using $R_a = \\sum_{b \\in upper(a)}$ where upper(a) denotes the upper-layer neurons connected to neuron 'a'. This is the major difference of the relevance representation. \n",
    "\n",
    "\n",
    "ii)  \n",
    "\n",
    "The authors have validated the XAI approach, at the document level, by building document heatmap visualizations, and at the dataset level, by compiling representative words for a text category. Furthermore authors have also shown quantitatively that LRP better identifies relevant words than sensitivity analysis.\n",
    "\n",
    "iii)  \n",
    "\n",
    "The weighted redistribution formula described in equation(4) of the given paper is used as a propagation rule for the convolutional layers. This is a variant of LRP-Œµ rules. \n",
    "We have strong weight sharing in the convolutions, this weight sharing often introduces spurious variations. Therefore, LRP-Œµ rules can help to filter these spurious variations. \n",
    "Max-pooling layers can be handled by a \"winner-take-all\" redistribution scheme.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42df9d87",
   "metadata": {},
   "source": [
    "#### b) Ethical AI\n",
    "\n",
    "Consider you are building a machine-learning based system for automatically recommending interesting talents as potential employees to start-ups:  The system scans publicly available personal and professional profiles on social media, code repositories, and other types of content outlets, generates unified profiles and classifies them to identify candidates who can be contacted for a fee.\n",
    "\n",
    "Name three challenges or threats to the ethical design of this system which you could encounter. Furthermore, discuss whether explainable AI can help to address or identify one (or more) of these threats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066be60",
   "metadata": {},
   "source": [
    "Few challenges or threats to the ethical design are,\n",
    "- model can have certain biases; over representing certern groups(white males, age groups, sexist, high income backgound, etc) and under representing certain minority groups or discriminate marginalized groups\n",
    "- obtain or copy certain source codes, files or descriptions in repositories without specific public open source licences\n",
    "- then the safety of personal information can be considered as another ethical challenge / transparency about data collection\n",
    "\n",
    "\n",
    "Explainable AI (XAI) can be used to identify these issues or to address these issues. XAI can be used to explian the model decisions, and how parts of the model influence its output, usually through the creation of a secondary model. Layerwise Relevance Propagation (LRP), LIME approach, Shapley Additive explanations are few methods we can implement here for creating an explainable AI.  \n",
    "\n",
    "In this example, text training data have to be used. However, text data is never curated manually due to its size. Therefore, text training data is ususally crawled automatically. This can result model biases. XAI can be used to explain what kind of data was used to train the system, how input can be changed to obtain a specific predictions, how a certain prediction is achieved etc.\n",
    "This explanatory information provided by the XAI can then be used to underestand why a bias has occured, which data has led to the specific bias, and how to eliminate the bias. For example, a LRP method can be used to analysis the model. This may be able to reveal serious consequences with impacts on society and individuals such as discriminating marginalized groups. Then this information can be used to eliminate or reduce this disciminatory behavior through addition of specific training data etc.   \n",
    "\n",
    "Another example is to use the XAI to improve the models and to make it more trustworthy. That way the model will not copy codes, files or descriptions on repositories that haven't provided opensource licences. And improving the trustworthiness through XAI can increase the safety of the presonal information handeling, and to aviod data leaks to 3rd parties etc.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfd017b6",
   "metadata": {},
   "source": [
    "### Design Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344be05",
   "metadata": {},
   "source": [
    "Assume that you want to create a mobile app which takes users through a dialog in which they provide speech, text, and image input (not necessarily all three) through their phone and then get medical advice from an AI module processing this input.\n",
    "\n",
    "i) Pick a concrete example of what type of service your app could offer (i.e., what type of medical advice based on what type of input). Formulate the machine learning problem(s) associated to this example.\n",
    "\n",
    "ii) For your example from i), describe how you would design the data set used to train the machine learning model. What existing or new data sources would you use? Be as concrete as possible, e.g., referencing existing real-world data sets, if applicable. For new data set, explain how you would acquire it. Justify your design decisions according to the criteria from the lecture. \n",
    "\n",
    "iii) Give two examples of explanation needs your end users could have when using your app from i). For both examples, say in 2-3 sentences how you would generate and present such explanations to the user."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3af47a9a",
   "metadata": {},
   "source": [
    "<b>1.</b>  \n",
    "<b>General details about the solution:</b>\n",
    "\n",
    "Our solution would be an application that could help people with common and non-life-threatening medical conditions. The objective is to design the app in a way that it would mimic the task of a GP to a certain extent and therefore reduce the number of GP visits by patients. Medical conditions which require specialist treatments are not covered. The application will be available in English.\n",
    "\n",
    "Overall, the app could offer medical advices to people regarding multiple health issues\". After trying to identify the specific health issue, \n",
    "1. If it is a health issue that the app can give the medical advice for, then it will do so.  \n",
    "2. If the identified issue is beyond app's scope of assisting with regards to, it will tell the patient about the what the identified health issue might be and ask them to see a doctor.\n",
    "   Service can only identify a fixed number of issues, and the number of issues it is able to give medical advice on is even lesser. Examples of this are common medical conditions such as common respiratory illnesses, food and digestive system infections, common urological issues, basic skin issues etc.  \n",
    "3. If the app is not able to identify the health issue, then it will tell the patient that the app is not able to identify the health issue and ask them to see a doctor.\n",
    "\n",
    "the type of input to the app can be speech or text (based on users‚Äô preference/they can choose between text or speech) and following up images for gaining additional information in special cases.\n",
    "\n",
    "<b>Technical architecture of the solution:<b>\n",
    "\n",
    "![](architecture_diagram.jpg)\n",
    "\n",
    "Let's look at a few use cases to further understand the internal operation of the app\n",
    "\n",
    "1. Patient 1: \n",
    "   Initial user utterance: \"I have headache, runny nose, sore throat\"\n",
    "   Initial classification: Flu (Confidence score:  85%), Sinus infection (Confidence score 65%)\n",
    "   App ask for additional information: body temperature (if available), age, gender and a photo of the throat -> Rule based system redirects to the binary classifier that has been trainied to identify flu\n",
    "   Output of the second stage classifier: True (Flu confirmed)\n",
    "   App provides medical advice (Take paracetamol for headache, Rest well, Drink more fluids, See a doctor if symptoms does not go away within 1 week etc.)\n",
    "\n",
    "2. Patient 2: \n",
    "   Initial user utterance: \"I have headache, seizures and vision problems\"\n",
    "   Initial classification: Nervous breakdown (Confidence score:  55%)\n",
    "   App is not able to give further medical advice and recommend see a doctor immediately\n",
    "\n",
    "<b>Formulation of the machine learning problems:</b>\n",
    "\n",
    "In the classification we have three specific machine learning problems\n",
    "1. Speech to text conversation\n",
    "   This component should convert the speech input that comes from the user to text format. A possible architecture for this component could be a model with a CNN followed by an RNN and finally\n",
    "   a linear layer with Softmax. The Convolutional network takes waves as the input and outputs feature maps which will be fed to Recurrent model (with LSTM) and finally the linear layer with SoftMax will output the likeliness of what the character might be for each time stamp.  \n",
    "    \n",
    "2. Initial health issue classification\n",
    "   Task of this stage is to classify the health issue (we can also call this intent) using the user utterance. In this part also an RNN model could be used, with a Softmax linear layer at the end to rank the health issues. Input to this component is the user utterance that comes directly from the user of from the speech to text engine.\n",
    "\n",
    "3. Second stage health issue classification (binary classifier that confirms the initail classification)\n",
    "   This stage has multiple trained classifiers. In this stage the input could be data of multiple types (Ex: an image of a certain body part together with age and body temperature).\n",
    "   This problem could be tackled using multiple architectures. One would be to flatten the image and feed it to the network together with other inputs. The network type would be a CNN\n",
    "   with a single Sigmoid output.\n",
    "\n",
    "\n",
    "<b>2.</b>  \n",
    "<b>\n",
    "Since the last stage of our application has a stage with multiple parallel classifiers(only one is relevant for any given case), we will single out one classifier from the this stage to explain the data selection of the end to end system, in relation to one of the many possible use cases</b>\n",
    "   \n",
    "<b>Selected use case: identifying Dermatitis(a common skin condition)</b>\n",
    "\n",
    "1. Speech to text conversion engine  \n",
    "    Dataset for this network should contain audio samples with corresponding text, given as a sequence, divided by  time intervals. Considering the working language of the app, English speech recognition should be considered in this case. Many such speech recognition datasets are available in the public domain. The characteristics of the database we are looking for are\n",
    "    - should contain enough samples to train the model\n",
    "    - should be diverse (different accents)\n",
    "    - should have data of different qualities (to mimic different environments and audio captured from different hardware with different level of details)\n",
    "\"GigaSpeech\"(https://github.com/SpeechColab/GigaSpeech) is a very good dataset with all the above discribed characteristics.\n",
    "\"tedlium\"(https://www.tensorflow.org/datasets/catalog/tedlium) is another dataset that can be considered.  \n",
    "\n",
    "    Another point to emphasize is that, if multiple data sources are combined, they should be brought into a similar format.\n",
    "    \n",
    "2. Initial health issue classification  \n",
    "    Dataset for this network should contain user utterances labled with health issues or illnesses they describe(intents). This is a specialized dataset that can be obtained by,\n",
    "    - from datasets in the public domain. One example would be \"Medical Speech, Transcription, and Intent\" database(https://www.kaggle.com/datasets/paultimothymooney/medical-speech-transcription-and-intent)  \n",
    "    In this approach it should be thoroughly verified that the data has come from credible sources.\n",
    "    - obtaining sets of symptoms for different health issues from medical professionals. Then user utterances should be formed that describe those symptom combinations. That can be done manually or using some sort of automation mechanism that forms sentences.\n",
    "    - ask patients that are confirmed to have the health issue to describe what they are feeling. This should be a voluntary process and should be done with patient's full consent.  \n",
    "    \n",
    "3. Second stage health issue classification (binary classifier that confirms the initial classification)  \n",
    "    Dataset for this model should be flattened image data combined together with (or without) other user parameters.  \n",
    "    Firstly, for a given health issue:  \n",
    "    Images can be obtained from many existing medical databases and other issue specific parameters should be obtained from medical professionals. Images can also be obtained by crowdsourcing, through an online portal for example.\n",
    "    If images are obtained from public domain credibility of the sources should be taken into account.  \n",
    "    In the case of Dermatitis,   \n",
    "    There are medical databases such as \"Dermnet\" database (https://www.kaggle.com/datasets/shubhamgoel27/dermnet) to obtain images.  \n",
    "    It should be emphasized that the obtained images should not result in any sort of discrimination in its classification. Therefore, it should have enough diversity (should cover different skin colors for example) \n",
    "    \n",
    "\n",
    "<b>3.</b>  \n",
    "    <b>\"What health problems can this app help to identify?\"</b>  \n",
    "    Firstly, we can include this as a question intent, with a specific label, in the initial health issue classifier, alongside with health issue. When it is detected, we can pre-program the rule-based system to generate a list of health issues that the app can assist with regards to and show it to the user through the front-end interface.   \n",
    "    <b>\"How did you reach to this diagnosis?\"</b>  \n",
    "    Classification of the question intent should be like above. Layer wise Relevance Propagation could be used to look back through the network and identify which features(symptoms, image features) contributed mostly for the conclusion. Then the conclusion can be brought into a pre-defined format and presented to the user through the frontend.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a42f56",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "71b202ce2822e786ea4fdfe3f0305cc84db1dc345efe5c7a2eefa65cade9eecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
